This project implements and evaluates a multimodal interaction paradigm for Subcomponent Selection Tasks in Virtual Reality. As VR environments grow in complexity, selecting specific, small targets nested within dense volumetric clusters becomes difficult due to occlusion and depth ambiguity.

This repository contains the implementation of a Gaze-Assisted 3D Pointer that combines:

Eye Tracking for coarse acquisition (defining the active volume).

Hand Tracking for fine manipulation (controlling the 3D pointer).

Developed as part of a Master's 10 ECTS Project Work at Aarhus University, this project presents three different application scenarios on the Meta Quest Pro following the study from my research project in 3DUI course : [https:/.](https://github.com/platak1sm/3DUI).
